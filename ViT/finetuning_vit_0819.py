# -*- coding: utf-8 -*-
"""FineTuning ViT_0819.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KkSUR6muBu3d1A3s1GnFL-fNVneKzgf3

### Head
"""

from google.colab import drive
drive.mount('/content/drive')

from transformers import TrOCRProcessor, VisionEncoderDecoderModel
from torchsummary import summary

# 모델과 프로세서를 불러옵니다.
model = VisionEncoderDecoderModel.from_pretrained("microsoft/trocr-small-handwritten")
processor = TrOCRProcessor.from_pretrained("microsoft/trocr-small-handwritten")

encoder = model.encoder
print(encoder)

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader, random_split
from torchvision import datasets, transforms
import copy


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

def process_image(image):
    processed_image = processor(images=image, return_tensors="pt").pixel_values
    return processed_image.squeeze(0)

size = (384, 384)

train_data_augmentation = transforms.Compose([
    transforms.Lambda(process_image),
    transforms.RandomResizedCrop(size),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(degrees=2),
    # transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
])

val_data_augmentation = transforms.Compose([
    transforms.Lambda(process_image),
    transforms.CenterCrop(size),
    # transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Rescaling(scale=1.0 / 127.5, offset=-1) 적용  ...?
])

train_dir = "/content/drive/MyDrive/split_dataset/train"
val_dir = "/content/drive/MyDrive/split_dataset/val"
test_dir = "/content/drive/MyDrive/split_dataset/test"

train_dataset = ImageFolder(
    root=train_dir,
    transform=train_data_augmentation
)
val_dataset = ImageFolder(
    root=val_dir,
    transform=val_data_augmentation
)
test_dataset = ImageFolder(
    root=test_dir,
    transform=transforms.Lambda(process_image)
)

train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)

"""### CLS token 추출 형태"""

import torch.nn.init as init

class Classifier(nn.Module):
    def __init__(self):
        super(Classifier, self).__init__()
        # self.global_avg_pool = nn.AdaptiveAvgPool1d(1)  # GlobalAveragePooling1D에 해당
        self.dropout1 = nn.Dropout(0.1)
        # self.fc1 = nn.Linear(578, 2048)
        self.fc1 = nn.Linear(384, 2048)
        self.relu = nn.ReLU()
        self.dropout2 = nn.Dropout(0.1)
        self.fc2 = nn.Linear(2048, 1024)
        self.relu = nn.ReLU()
        self.dropout3 = nn.Dropout(0.1)
        self.fc3 = nn.Linear(1024, 2)  # 2 클래스에 대한 출력

        self._initialize_weights()

    def forward(self, x):
        # x = self.global_avg_pool(x).squeeze(-1)  # (batch_size, 578)
        x = x[:, 0, :]
        x = self.dropout1(x)
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout2(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout3(x)
        x = self.fc3(x)
        return x

    def _initialize_weights(self):
        # He initialization for layers followed by ReLU
        for layer in self.modules():
            if isinstance(layer, nn.Linear):
                init.kaiming_normal_(layer.weight, nonlinearity='relu')
                if layer.bias is not None:
                    init.constant_(layer.bias, 0)

class WholeModel(nn.Module):
    def __init__(self, encoder, classifier):
        super(WholeModel, self).__init__()
        self.encoder = encoder
        self.classifier = classifier

    def forward(self, x):
        x = self.encoder(x)
        x = x[0]
        x = self.classifier(x)
        return x

classifier = Classifier()
model = WholeModel(encoder, classifier).to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(classifier.parameters(), lr=0.005)
# optimizer를 wholeModel로 써서

from torch.optim.lr_scheduler import StepLR

# 학습 스케줄러 설정
scheduler = StepLR(optimizer, step_size=10, gamma=0.1)

epochs = 10

train_losses = []
val_losses = []

for epoch in range(epochs):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0

    for inputs, labels in train_loader:
        inputs = inputs.to(device)
        labels = labels.to(device)

        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item() * labels.size(0)
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
    scheduler.step()

    train_loss = running_loss / total
    train_losses.append(train_loss)
    train_accuracy = correct / total

    model.eval()
    val_loss = 0.0
    val_correct = 0
    val_total = 0
    with torch.no_grad():
        for inputs, labels in val_loader:
            inputs = inputs.to(device)
            labels = labels.to(device)

            outputs = model(inputs)
            loss = criterion(outputs, labels)
            val_loss += loss.item() * labels.size(0)
            _, predicted = torch.max(outputs, 1)
            val_total += labels.size(0)
            val_correct += (predicted == labels).sum().item()

    val_loss /= val_total
    val_losses.append(val_loss)
    val_accuracy = val_correct / val_total

    print(f'Epoch {epoch+1}/{epochs}, '
          f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, '
          f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')

"""### MultiScale ViT(Patch 8,16 해상도 224, 112)"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim.lr_scheduler import StepLR
from transformers import TrOCRProcessor, VisionEncoderDecoderModel

# MultiScaleViT 클래스 정의
class MultiScaleViT(nn.Module):
    def __init__(self, encoder, num_classes=2):
        super(MultiScaleViT, self).__init__()
        self.encoder = encoder
        self.num_classes = num_classes

        # 패치 임베딩 레이어는 기존의 임베딩 방식을 사용하여 구현합니다.
        self.patch_size_8 = 8
        self.patch_size_16 = 16

        # Classification Head
        self.classifier = nn.Linear(encoder.config.hidden_size * 2, num_classes)

    def forward(self, x):
        batch_size = x.size(0)

        # 해상도 224에서 패치 크기 8 적용
        x1 = self.create_patches(x, patch_size=self.patch_size_8)
        cls_token_8 = self.encoder(x1)['last_hidden_state'][:, 0]

        # 해상도 112에서 패치 크기 16 적용
        x2 = self.create_patches(x, patch_size=self.patch_size_16, image_size=(112, 112))
        cls_token_16 = self.encoder(x2)['last_hidden_state'][:, 0]

        # 두 CLS 토큰을 결합
        cls_token_combined = torch.cat((cls_token_8, cls_token_16), dim=-1)

        # Classification Head
        logits = self.classifier(cls_token_combined)

        return logits

    def create_patches(self, x, patch_size, image_size=None):
        if image_size:
            x = torch.nn.functional.interpolate(x, size=image_size, mode='bilinear')

        batch_size, channels, height, width = x.shape

        # 패치를 만들기 위해 입력 이미지를 패치 크기 단위로 분할합니다.
        patches = x.unfold(2, patch_size, patch_size).unfold(3, patch_size, patch_size)
        patches = patches.contiguous().view(batch_size, channels, -1, patch_size * patch_size)
        patches = patches.permute(0, 2, 1, 3).contiguous().view(batch_size, -1, patch_size * patch_size * channels)

        # 패치들을 Linear Projection을 통해 임베딩 벡터로 변환
        linear_projection = nn.Linear(patch_size * patch_size * channels, self.encoder.config.hidden_size)
        x_patches = linear_projection(patches)

        return x_patches

# WholeModel 클래스 정의
class WholeModel(nn.Module):
    def __init__(self, encoder, classifier):
        super(WholeModel, self).__init__()
        self.encoder = encoder
        self.classifier = classifier

    def forward(self, x):
        x = self.encoder(x)
        return x

# 장치 설정 (GPU 사용)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# MultiScaleViT 인코더를 사용하여 WholeModel 초기화
multi_scale_vit = MultiScaleViT(encoder=encoder, num_classes=2)
whole_model = WholeModel(encoder=multi_scale_vit, classifier=multi_scale_vit.classifier).to(device)

# 손실 함수와 옵티마이저 정의
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(whole_model.classifier.parameters(), lr=0.005)

# 학습 스케줄러 설정
scheduler = StepLR(optimizer, step_size=10, gamma=0.1)

# 학습 및 검증 데이터 로더 (미리 정의된 train_loader, val_loader 사용)
epochs = 10

train_losses = []
val_losses = []

for epoch in range(epochs):
    whole_model.train()
    running_loss = 0.0
    correct = 0
    total = 0

    for inputs, labels in train_loader:
        inputs = inputs.to(device)
        labels = labels.to(device)

        optimizer.zero_grad()
        outputs = whole_model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item() * labels.size(0)
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

    scheduler.step()

    train_loss = running_loss / total
    train_losses.append(train_loss)
    train_accuracy = correct / total

    whole_model.eval()
    val_loss = 0.0
    val_correct = 0
    val_total = 0
    with torch.no_grad():
        for inputs, labels in val_loader:
            inputs = inputs.to(device)
            labels = labels.to(device)

            outputs = whole_model(inputs)
            loss = criterion(outputs, labels)
            val_loss += loss.item() * labels.size(0)
            _, predicted = torch.max(outputs, 1)
            val_total += labels.size(0)
            val_correct += (predicted == labels).sum().item()

    val_loss /= val_total
    val_losses.append(val_loss)
    val_accuracy = val_correct / val_total

    print(f'Epoch {epoch+1}/{epochs}, '
          f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, '
          f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')

"""### CNN"""

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader, random_split
import torch.nn.init as init

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# CNN 모델 정의 (ResNet18을 베이스로 사용)
class Classifier(nn.Module):
    def __init__(self):
        super(Classifier, self).__init__()
        self.resnet = models.resnet18(pretrained=True)
        num_ftrs = self.resnet.fc.in_features
        self.resnet.fc = nn.Linear(num_ftrs, 512)  # ResNet 출력에 맞게 Linear 레이어 추가
        self.dropout = nn.Dropout(0.5)
        self.fc = nn.Linear(512, 2)  # 2 클래스에 대한 출력

        self._initialize_weights()

    def forward(self, x):
        x = self.resnet(x)
        x = self.dropout(x)
        x = self.fc(x)
        return x

    def _initialize_weights(self):
        # He initialization for layers followed by ReLU
        for layer in self.modules():
            if isinstance(layer, nn.Linear):
                init.kaiming_normal_(layer.weight, nonlinearity='relu')
                if layer.bias is not None:
                    init.constant_(layer.bias, 0)

model = Classifier().to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.005)

from torch.optim.lr_scheduler import StepLR

# 학습 스케줄러 설정
scheduler = StepLR(optimizer, step_size=10, gamma=0.1)

epochs = 10

train_losses = []
val_losses = []

for epoch in range(epochs):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0

    for inputs, labels in train_loader:
        inputs = inputs.to(device)
        labels = labels.to(device)

        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item() * labels.size(0)
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
    scheduler.step()

    train_loss = running_loss / total
    train_losses.append(train_loss)
    train_accuracy = correct / total

    model.eval()
    val_loss = 0.0
    val_correct = 0
    val_total = 0
    with torch.no_grad():
        for inputs, labels in val_loader:
            inputs = inputs.to(device)
            labels = labels.to(device)

            outputs = model(inputs)
            loss = criterion(outputs, labels)
            val_loss += loss.item() * labels.size(0)
            _, predicted = torch.max(outputs, 1)
            val_total += labels.size(0)
            val_correct += (predicted == labels).sum().item()

    val_loss /= val_total
    val_losses.append(val_loss)
    val_accuracy = val_correct / val_total

    print(f'Epoch {epoch+1}/{epochs}, '
          f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, '
          f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')

"""### WholeModel Optimizer"""

import torch.nn.init as init

class Classifier(nn.Module):
    def __init__(self):
        super(Classifier, self).__init__()
        # self.global_avg_pool = nn.AdaptiveAvgPool1d(1)  # GlobalAveragePooling1D에 해당
        self.dropout1 = nn.Dropout(0.1)
        # self.fc1 = nn.Linear(578, 2048)
        self.fc1 = nn.Linear(384, 2048)
        self.relu = nn.ReLU()
        self.dropout2 = nn.Dropout(0.1)
        self.fc2 = nn.Linear(2048, 1024)
        self.relu = nn.ReLU()
        self.dropout3 = nn.Dropout(0.1)
        self.fc3 = nn.Linear(1024, 2)  # 2 클래스에 대한 출력

        self._initialize_weights()

    def forward(self, x):
        # x = self.global_avg_pool(x).squeeze(-1)  # (batch_size, 578)
        x = x[:, 0, :]
        x = self.dropout1(x)
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout2(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout3(x)
        x = self.fc3(x)
        return x

    def _initialize_weights(self):
        # He initialization for layers followed by ReLU
        for layer in self.modules():
            if isinstance(layer, nn.Linear):
                init.kaiming_normal_(layer.weight, nonlinearity='relu')
                if layer.bias is not None:
                    init.constant_(layer.bias, 0)

class WholeModel(nn.Module):
    def __init__(self, encoder, classifier):
        super(WholeModel, self).__init__()
        self.encoder = encoder
        self.classifier = classifier

    def forward(self, x):
        x = self.encoder(x)
        x = x[0]
        x = self.classifier(x)
        return x

classifier = Classifier()
model = WholeModel(encoder, classifier).to(device)

criterion = nn.CrossEntropyLoss()

# 기존 코드의 optimizer를 WholeModel 전체에 걸리도록 수정
optimizer = optim.Adam(model.parameters(), lr=0.005)  # model.parameters()로 수정

from torch.optim.lr_scheduler import StepLR

# 학습 스케줄러 설정
scheduler = StepLR(optimizer, step_size=10, gamma=0.1)

epochs = 10

train_losses = []
val_losses = []

for epoch in range(epochs):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0

    for inputs, labels in train_loader:
        inputs = inputs.to(device)
        labels = labels.to(device)

        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item() * labels.size(0)
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
    scheduler.step()

    train_loss = running_loss / total
    train_losses.append(train_loss)
    train_accuracy = correct / total

    model.eval()
    val_loss = 0.0
    val_correct = 0
    val_total = 0
    with torch.no_grad():
        for inputs, labels in val_loader:
            inputs = inputs.to(device)
            labels = labels.to(device)

            outputs = model(inputs)
            loss = criterion(outputs, labels)
            val_loss += loss.item() * labels.size(0)
            _, predicted = torch.max(outputs, 1)
            val_total += labels.size(0)
            val_correct += (predicted == labels).sum().item()

    val_loss /= val_total
    val_losses.append(val_loss)
    val_accuracy = val_correct / val_total

    print(f'Epoch {epoch+1}/{epochs}, '
          f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, '
          f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')

"""### ImageClassifier(Pretained 안 된)"""

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import transforms, datasets, models
from torch.utils.data import DataLoader
from torchvision.datasets import ImageFolder

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# 데이터 경로 설정
train_dir = "/content/drive/MyDrive/split_dataset/train"
val_dir = "/content/drive/MyDrive/split_dataset/val"
test_dir = "/content/drive/MyDrive/split_dataset/test"

# 이미지 크기 설정
size = (224, 224)

# 데이터 증강 및 전처리 설정
train_data_augmentation = transforms.Compose([
    transforms.RandomResizedCrop(size),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(degrees=2),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
])

val_data_augmentation = transforms.Compose([
    transforms.CenterCrop(size),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
])

# 데이터셋 설정
train_dataset = ImageFolder(root=train_dir, transform=train_data_augmentation)
val_dataset = ImageFolder(root=val_dir, transform=val_data_augmentation)
test_dataset = ImageFolder(root=test_dir, transform=val_data_augmentation)

# 데이터 로더 설정
train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)

# Vision Transformer 모델 설정 (사전 학습되지 않은 상태)
vit_model = models.vit_b_16(weights=None)  # pretrained 대신 weights=None으로 수정

# 마지막 분류 층 수정
vit_model.heads.head = nn.Linear(vit_model.heads.head.in_features, 2)  # 클래스 개수에 맞게 수정

vit_model = vit_model.to(device)

# 손실 함수 및 최적화 도구 설정
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(vit_model.parameters(), lr=0.001)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)

# 학습 루프
epochs = 10
train_losses = []
val_losses = []

for epoch in range(epochs):
    vit_model.train()
    running_loss = 0.0
    correct = 0
    total = 0

    for inputs, labels in train_loader:
        inputs, labels = inputs.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = vit_model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item() * labels.size(0)
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

    scheduler.step()

    train_loss = running_loss / total
    train_losses.append(train_loss)
    train_accuracy = correct / total

    vit_model.eval()
    val_loss = 0.0
    val_correct = 0
    val_total = 0
    with torch.no_grad():
        for inputs, labels in val_loader:
            inputs, labels = inputs.to(device), labels.to(device)

            outputs = vit_model(inputs)
            loss = criterion(outputs, labels)
            val_loss += loss.item() * labels.size(0)
            _, predicted = torch.max(outputs, 1)
            val_total += labels.size(0)
            val_correct += (predicted == labels).sum().item()

    val_loss /= val_total
    val_losses.append(val_loss)
    val_accuracy = val_correct / val_total

    print(f'Epoch {epoch+1}/{epochs}, '
          f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, '
          f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')

