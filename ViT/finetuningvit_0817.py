# -*- coding: utf-8 -*-
"""FineTuningViT_0817.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zl1I_sYMhnr2NBfESN4qAOAUCQgXD6Lh
"""

from google.colab import drive
drive.mount('/content/drive')

"""### 베이스라인 시작부분"""

from transformers import TrOCRProcessor, VisionEncoderDecoderModel
from torchsummary import summary

# 모델과 프로세서를 불러옵니다.
model = VisionEncoderDecoderModel.from_pretrained("microsoft/trocr-small-handwritten")
processor = TrOCRProcessor.from_pretrained("microsoft/trocr-small-handwritten")

encoder = model.encoder
print(encoder)

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader, random_split
from torchvision import transforms
from transformers import TrOCRProcessor, VisionEncoderDecoderModel

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

def process_image(image):
    processed_image = processor(images=image, return_tensors="pt").pixel_values
    return processed_image.squeeze(0)

data_dir = "/content/drive/MyDrive/Data"

# ImageFolder를 통해 데이터셋 생성
dataset = ImageFolder(
    root=data_dir,
    transform=transforms.Lambda(process_image)
)
train_size = int(0.6 * len(dataset))
val_size = int(0.2 * len(dataset))
test_size = len(dataset) - train_size - val_size

train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])


train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

class Classifier(nn.Module):
    def __init__(self):
        super(Classifier, self).__init__()
        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)  # GlobalAveragePooling1D에 해당
        self.dropout1 = nn.Dropout(0.1)
        self.fc1 = nn.Linear(578, 128)  # 입력 크기 577, 출력 크기 128
        self.relu = nn.ReLU()
        self.dropout2 = nn.Dropout(0.1)
        self.fc2 = nn.Linear(128, 2)  # 2 클래스에 대한 출력

    def forward(self, x):
        x = self.global_avg_pool(x).squeeze(-1)  # (batch_size, 577)
        x = self.dropout1(x)
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout2(x)
        x = self.fc2(x)
        return x

class SelectOutput(nn.Module):
    def forward(self, x):
        return x[0]

classifier = Classifier()
model = nn.Sequential(encoder, SelectOutput(), classifier).to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(classifier.parameters(), lr=1e-4)

epochs = 10

train_losses = []
val_losses = []

for epoch in range(epochs):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0

    for inputs, labels in train_loader:
        inputs = inputs.to(device)
        labels = labels.to(device)

        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

    train_loss = running_loss / total
    train_losses.append(train_loss)
    train_accuracy = correct / total

    model.eval()
    val_loss = 0.0
    val_correct = 0
    val_total = 0
    with torch.no_grad():
        for inputs, labels in val_loader:
            inputs = inputs.to(device)
            labels = labels.to(device)

            outputs = model(inputs)
            loss = criterion(outputs, labels)
            val_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            val_total += labels.size(0)
            val_correct += (predicted == labels).sum().item()

    val_loss /= val_total
    val_losses.append(val_loss)
    val_accuracy = val_correct / val_total

    print(f'Epoch {epoch+1}/{epochs}, '
          f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, '
          f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')

"""### Multi-Scale Patch Embedding ver.2"""

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader, random_split
from torchvision import transforms
from transformers import TrOCRProcessor, VisionEncoderDecoderModel
import copy

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# 이미지 전처리 함수
def process_image(image, target_size=(224, 224)):
    transform = transforms.Compose([
        transforms.Resize(target_size),  # 이미지 크기 조정
        transforms.ToTensor()  # 이미지 텐서로 변환
    ])
    return transform(image)

# Multi-Scale ViT 구현
class MultiScaleViT(nn.Module):
    def __init__(self, encoder, scales=[16, 8], output_dim=128):
        super(MultiScaleViT, self).__init__()
        self.encoders = nn.ModuleList([copy.deepcopy(encoder) for _ in scales])
        self.fc = nn.Linear(len(scales) * encoder.config.hidden_size, output_dim)

    def forward(self, image):
        features = []
        for encoder in self.encoders:
            processed_image = processor(images=image, return_tensors="pt").pixel_values.to(image.device)
            feature = encoder(processed_image)[0]  # (batch, seq_len, hidden_size)
            features.append(feature.mean(dim=1))  # (batch, hidden_size)

        combined_features = torch.cat(features, dim=-1)  # (batch, len(scales) * hidden_size)
        output = self.fc(combined_features)  # (batch, output_dim)
        return output

# Classifier 정의
class Classifier(nn.Module):
    def __init__(self, encoder, scales=[16, 8], num_classes=2):
        super(Classifier, self).__init__()
        self.multi_scale_vit = MultiScaleViT(encoder, scales=scales)
        self.dropout = nn.Dropout(0.1)
        self.fc = nn.Linear(128, num_classes)  # 최종 분류를 위한 레이어

    def forward(self, x):
        x = self.multi_scale_vit(x)
        x = self.dropout(x)
        x = self.fc(x)
        return x

# 데이터셋 처리
data_dir = "/content/drive/MyDrive/Data"

dataset = ImageFolder(
    root=data_dir,
    transform=process_image  # 이미지를 텐서로 변환하는 과정 포함
)

train_size = int(0.6 * len(dataset))
val_size = int(0.2 * len(dataset))
test_size = len(dataset) - train_size - val_size

train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

# 모델 초기화
classifier = Classifier(encoder, scales=[16, 8]).to(device)

# 학습 루프
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(classifier.parameters(), lr=1e-4)

epochs = 10

for epoch in range(epochs):
    classifier.train()
    running_loss = 0.0
    correct = 0
    total = 0

    for inputs, labels in train_loader:
        inputs = inputs.to(device)
        labels = labels.to(device)

        optimizer.zero_grad()
        outputs = classifier(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

    train_loss = running_loss / total
    train_accuracy = correct / total

    classifier.eval()
    val_loss = 0.0
    val_correct = 0
    val_total = 0
    with torch.no_grad():
        for inputs, labels in val_loader:
            inputs = inputs.to(device)
            labels = labels.to(device)

            outputs = classifier(inputs)
            loss = criterion(outputs, labels)
            val_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            val_total += labels.size(0)
            val_correct += (predicted == labels).sum().item()

    val_loss /= val_total
    val_accuracy = val_correct / val_total

    print(f'Epoch {epoch+1}/{epochs}, '
          f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, '
          f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')

"""- 웅 램 다운..

#### WHY?
- 서로 다른 패치 크기를 처리하기 위해 인코더 여러 개 복제
- 그래서 각 복제본이 동일한 크기의 모델 파마리터를 가지고 있어서 메모리 많이 사용
- 아니면, 각 패치 크기에 대해 독립적으로 이미지 처리 수행하므로, 메모리내에서 이미지가 여러번 복제

### Dynamic Token Pooling

**구현 계획**
- 동적 선택: 중요도가 높은 패치를 선택하거나 가중치를 부여하여 더 집중적으로 학습
- 이걸 하고나서 이따가 다시 멀티스케일 패치 임베딩 하면 될 수도..?
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader, random_split
from torchvision import transforms
from transformers import TrOCRProcessor, VisionEncoderDecoderModel

# 모델과 프로세서를 불러옵니다.
model = VisionEncoderDecoderModel.from_pretrained("microsoft/trocr-small-handwritten")
processor = TrOCRProcessor.from_pretrained("microsoft/trocr-small-handwritten")

encoder = model.encoder
hidden_size = encoder.config.hidden_size  # encoder의 hidden_size를 가져옴

# 자꾸 뒤에 시퀀스 길이가 안맞아서 그냥 16X16 +2로 할래
seq_len = 198  # 위치 임베딩 문제를 해결하기 위해 시퀀스 길이를 198로 설정
print(f"Hidden size: {hidden_size}, Sequence Length: {seq_len}")

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Dynamic Token Pooling 클래스 정의
class DynamicTokenPooling(nn.Module):
    def __init__(self, hidden_size, num_tokens):
        super(DynamicTokenPooling, self).__init__()
        self.attention = nn.Linear(hidden_size, 1)  # 각 토큰의 중요도를 계산하는 attention layer
        self.softmax = nn.Softmax(dim=1)  # 중요도에 따라 토큰 선택을 확률적으로

    def forward(self, x):
        # x: (batch_size, seq_len, hidden_size)
        attention_scores = self.attention(x)  # (batch_size, seq_len, 1)
        attention_scores = self.softmax(attention_scores)  # (batch_size, seq_len, 1)
        x = x * attention_scores  # 중요도가 반영된 토큰들
        pooled = x.sum(dim=1)  # 모든 토큰을 종합하여 하나의 벡터로 압축
        return pooled

# Classifier 정의
class Classifier(nn.Module):
    def __init__(self, encoder, hidden_size, num_tokens, num_classes=2):
        super(Classifier, self).__init__()
        self.encoder = encoder
        self.token_pooling = DynamicTokenPooling(hidden_size, num_tokens=num_tokens)
        self.dropout = nn.Dropout(0.1)
        self.fc = nn.Linear(hidden_size, num_classes)

    def forward(self, x):
        x = self.encoder(x)[0]  # (batch_size, seq_len, hidden_size)
        x = self.token_pooling(x)  # Dynamic Token Pooling 적용
        x = self.dropout(x)
        x = self.fc(x)
        return x

# 데이터셋 처리
def process_image(image, target_size=(224, 224)):
    resized_image = transforms.Resize(target_size)(image)
    return resized_image

data_dir = "/content/drive/MyDrive/Data"

transform = transforms.Compose([
    transforms.Lambda(lambda img: process_image(img)),
    transforms.ToTensor()  # PIL 이미지를 텐서로 변환합니다.
])

dataset = ImageFolder(
    root=data_dir,
    transform=transform
)

train_size = int(0.6 * len(dataset))
val_size = int(0.2 * len(dataset))
test_size = len(dataset) - train_size - val_size

train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

# 모델 초기화
classifier = Classifier(encoder, hidden_size=hidden_size, num_tokens=seq_len).to(device)

# 학습 루프
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(classifier.parameters(), lr=1e-4)

epochs = 10

for epoch in range(epochs):
    classifier.train()
    running_loss = 0.0
    correct = 0
    total = 0

    for inputs, labels in train_loader:
        inputs = inputs.to(device)
        labels = labels.to(device)

        optimizer.zero_grad()
        outputs = classifier(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

    train_loss = running_loss / total
    train_accuracy = correct / total

    classifier.eval()
    val_loss = 0.0
    val_correct = 0
    val_total = 0
    with torch.no_grad():
        for inputs, labels in val_loader:
            inputs = inputs.to(device)
            labels = labels.to(device)

            outputs = classifier(inputs)
            loss = criterion(outputs, labels)
            val_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            val_total += labels.size(0)
            val_correct += (predicted == labels).sum().item()

    val_loss /= val_total
    val_accuracy = val_correct / val_total

    print(f'Epoch {epoch+1}/{epochs}, '
          f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, '
          f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')

"""141         embeddings = embeddings + position_embedding

RuntimeError: The size of tensor a (198) must match the size of tensor b (578) at non-singleton dimension 1

**원인분석**
- embeddings 텐서는 224/16 = 14의 제곱이므로 총 패치수는 196+2
- position_embedding 텐서는 ViT 모델 입력이 578 길이를 기대함
"""

# import torch
# import torch.nn as nn
# import torch.optim as optim
# from torchvision.datasets import ImageFolder
# from torch.utils.data import DataLoader, random_split
# from torchvision import transforms
# from transformers import TrOCRProcessor, VisionEncoderDecoderModel

# # 모델과 프로세서를 불러옵니다.
# model = VisionEncoderDecoderModel.from_pretrained("microsoft/trocr-small-handwritten")
# processor = TrOCRProcessor.from_pretrained("microsoft/trocr-small-handwritten")

encoder = model.encoder
hidden_size = encoder.config.hidden_size  # encoder의 hidden_size를 가져옴
seq_len = encoder.config.image_size // encoder.config.patch_size  # 패치 수 계산
seq_len = (seq_len ** 2) + 2  # 패치 수에 CLS 토큰 추가
print(f"Hidden size: {hidden_size}, Sequence Length: {seq_len}")

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Dynamic Token Pooling 클래스 정의
class DynamicTokenPooling(nn.Module):
    def __init__(self, hidden_size, num_tokens):
        super(DynamicTokenPooling, self).__init__()
        self.attention = nn.Linear(hidden_size, 1)  # 각 토큰의 중요도를 계산하는 attention layer
        self.softmax = nn.Softmax(dim=1)  # 중요도에 따라 토큰 선택을 확률적으로

    def forward(self, x):
        # x: (batch_size, seq_len, hidden_size)
        attention_scores = self.attention(x)  # (batch_size, seq_len, 1)
        attention_scores = self.softmax(attention_scores)  # (batch_size, seq_len, 1)
        x = x * attention_scores  # 중요도가 반영된 토큰들
        pooled = x.sum(dim=1)  # 모든 토큰을 종합하여 하나의 벡터로 압축
        return pooled

# Classifier 정의
class Classifier(nn.Module):
    def __init__(self, encoder, hidden_size, num_tokens, num_classes=2):
        super(Classifier, self).__init__()
        self.encoder = encoder
        self.token_pooling = DynamicTokenPooling(hidden_size, num_tokens=num_tokens)
        self.dropout = nn.Dropout(0.1)
        self.fc = nn.Linear(hidden_size, num_classes)

    def forward(self, x):
        x = self.encoder(x)[0]  # (batch_size, seq_len, hidden_size) 여기서 seq_len은 198 또는 578
        if x.size(1) != num_tokens:
            x = x[:, :num_tokens, :]  # 필요에 따라 seq_len을 맞춰줌
        x = self.token_pooling(x)  # Dynamic Token Pooling 적용 (batch_size, hidden_size)
        x = self.dropout(x)
        x = self.fc(x)  # (batch_size, num_classes)
        return x

# 데이터셋 처리
def process_image(image, target_size=(224, 224)):
    resized_image = transforms.Resize(target_size)(image)
    return resized_image

data_dir = "/content/drive/MyDrive/Data"

transform = transforms.Compose([
    transforms.Lambda(lambda img: process_image(img)),
    transforms.ToTensor()  # PIL 이미지를 텐서로 변환합니다.
])

dataset = ImageFolder(
    root=data_dir,
    transform=transform
)

train_size = int(0.6 * len(dataset))
val_size = int(0.2 * len(dataset))
test_size = len(dataset) - train_size - val_size

train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

# 모델 초기화
classifier = Classifier(encoder, hidden_size=hidden_size, num_tokens=seq_len).to(device)

# 학습 루프
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(classifier.parameters(), lr=1e-4)

epochs = 10

for epoch in range(epochs):
    classifier.train()
    running_loss = 0.0
    correct = 0
    total = 0

    for inputs, labels in train_loader:
        inputs = inputs.to(device)
        labels = labels.to(device)

        optimizer.zero_grad()
        outputs = classifier(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

    train_loss = running_loss / total
    train_accuracy = correct / total

    classifier.eval()
    val_loss = 0.0
    val_correct = 0
    val_total = 0
    with torch.no_grad():
        for inputs, labels in val_loader:
            inputs = inputs.to(device)
            labels = labels.to(device)

            outputs = classifier(inputs)
            loss = criterion(outputs, labels)
            val_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            val_total += labels.size(0)
            val_correct += (predicted == labels).sum().item()

    val_loss /= val_total
    val_accuracy = val_correct / val_total

    print(f'Epoch {epoch+1}/{epochs}, '
          f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, '
          f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')

encoder = model.encoder
hidden_size = encoder.config.hidden_size  # encoder의 hidden_size를 가져옴

# 위치 임베딩 크기와 시퀀스 길이 확인
print(f"Expected Sequence Length (position_embedding): {(encoder.config.image_size // encoder.config.patch_size) ** 2 + 2}")
position_embeddings = encoder.embeddings.position_embeddings
print(f"Position Embedding Shape: {position_embeddings.shape}")

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Dynamic Token Pooling 클래스 정의
class DynamicTokenPooling(nn.Module):
    def __init__(self, hidden_size, num_tokens):
        super(DynamicTokenPooling, self).__init__()
        self.attention = nn.Linear(hidden_size, 1)  # 각 토큰의 중요도를 계산하는 attention layer
        self.softmax = nn.Softmax(dim=1)  # 중요도에 따라 토큰 선택을 확률적으로

    def forward(self, x):
        print(f"Input sequence length: {x.size(1)}")  # 입력 시퀀스 길이 출력
        attention_scores = self.attention(x)  # (batch_size, seq_len, 1)
        attention_scores = self.softmax(attention_scores)  # (batch_size, seq_len, 1)
        x = x * attention_scores  # 중요도가 반영된 토큰들
        pooled = x.sum(dim=1)  # 모든 토큰을 종합하여 하나의 벡터로 압축
        return pooled

# Classifier 정의
class Classifier(nn.Module):
    def __init__(self, encoder, hidden_size, num_tokens, num_classes=2):
        super(Classifier, self).__init__()
        self.encoder = encoder
        self.token_pooling = DynamicTokenPooling(hidden_size, num_tokens=num_tokens)
        self.dropout = nn.Dropout(0.1)
        self.fc = nn.Linear(hidden_size, num_classes)

    def forward(self, x):
        x = self.encoder(x)[0]  # (batch_size, seq_len, hidden_size)
        print(f"Encoded sequence length: {x.size(1)}")  # 인코딩된 시퀀스 길이 확인
        if x.size(1) != num_tokens:
            x = x[:, :num_tokens, :]  # 필요에 따라 seq_len을 맞춰줌
        x = self.token_pooling(x)  # Dynamic Token Pooling 적용 (batch_size, hidden_size)
        x = self.dropout(x)
        x = self.fc(x)  # (batch_size, num_classes)
        return x

# 데이터셋 처리
def process_image(image, target_size=(224, 224)):
    resized_image = transforms.Resize(target_size)(image)
    return resized_image

data_dir = "/content/drive/MyDrive/Data"

transform = transforms.Compose([
    transforms.Resize((224, 224)),  # 이미지 크기 강제 조정
    transforms.ToTensor()  # PIL 이미지를 텐서로 변환합니다.
])

dataset = ImageFolder(
    root=data_dir,
    transform=transform
)

train_size = int(0.6 * len(dataset))
val_size = int(0.2 * len(dataset))
test_size = len(dataset) - train_size - val_size

train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

# 모델 초기화
classifier = Classifier(encoder, hidden_size=hidden_size, num_tokens=578).to(device)

# 학습 루프
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(classifier.parameters(), lr=1e-4)

epochs = 10

for epoch in range(epochs):
    classifier.train()
    running_loss = 0.0
    correct = 0
    total = 0

    for inputs, labels in train_loader:
        inputs = inputs.to(device)
        labels = labels.to(device)

        optimizer.zero_grad()
        outputs = classifier(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

    train_loss = running_loss / total
    train_accuracy = correct / total

    classifier.eval()
    val_loss = 0.0
    val_correct = 0
    val_total = 0
    with torch.no_grad():
        for inputs, labels in val_loader:
            inputs = inputs.to(device)
            labels = labels.to(device)

            outputs = classifier(inputs)
            loss = criterion(outputs, labels)
            val_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            val_total += labels.size(0)
            val_correct += (predicted == labels).sum().item()

    val_loss /= val_total
    val_accuracy = val_correct / val_total

    print(f'Epoch {epoch+1}/{epochs}, '
          f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, '
          f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')

# 입력 이미지 크기와 패치 크기 확인
print(f"Patch Size: {encoder.config.patch_size}")
print(f"Image Size: {encoder.config.image_size}")

